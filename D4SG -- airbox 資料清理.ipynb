{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**選取資料(在各airbox 資料依各縣市分配)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"E:\\D4SG\\Data\\PM2.5 airbox\\PM2.5國網與中研院移除飄移.csv\", encoding = \"utf8\") as pm25:\n",
    "    line = pm25.readline()\n",
    "    want_address = {}    \n",
    "    remove_address = []  \n",
    "    google_address = {}  \n",
    "      \n",
    "    while line:\n",
    "        line = line.strip().split(\",\")\n",
    "        \n",
    "        try: \n",
    "            # the scope of latitude and longitude\n",
    "            if (21.890036 < float(line[7]) < 22.902293) & (120.315043 < float(line[8]) <120.919145):\n",
    "                station_id = line[2]\n",
    "                 \n",
    "                if station_id in remove_address:\n",
    "                    line = pm25.readline()\n",
    "                    continue\n",
    "                \n",
    "                elif (station_id not in want_address) and (station_id not in google_address):\n",
    "                    try:\n",
    "                        address = geocoder.arcgis(line[7:9], method = \"reverse\")\n",
    "                        \n",
    "                        if address.error == False:\n",
    "                            address = address.geojson['features'][0].get('properties').get(\"raw\").get(\"address\").get('LongLabel')\n",
    "                            \n",
    "                        else:\n",
    "                            while address.error == True:\n",
    "                                print(\"sleep.arcgis\")\n",
    "                                time.sleep(5)\n",
    "                                address = geocoder.arcgis(line[7:9], method = \"reverse\")\n",
    "                            \n",
    "                            address = address.geojson['features'][0].get('properties').get(\"raw\").get(\"address\").get('LongLabel')    \n",
    "                        \n",
    "                    except IndexError:\n",
    "                        address = geocoder.google(line[7:9], method = \"reverse\", language=\"zh-TW\", timeout=10)\n",
    "                        \n",
    "                        if address.error == False:\n",
    "                            address = address.current_result\n",
    "                            address = str(address).strip(\"[\").strip(\"]\")\n",
    "                        \n",
    "                        else:\n",
    "                            while address.error == True:\n",
    "                                print(\"sleep.google\")\n",
    "                                time.sleep(5)\n",
    "                                address = geocoder.google(line[7:9], method = \"reverse\", language=\"zh-TW\", timeout=10)                          \n",
    "                            \n",
    "                            address = address.current_result  \n",
    "                            address = str(address).strip(\"[\").strip(\"]\")\n",
    "                        \n",
    "                    if (\"屏東\" in address):   \n",
    "                        want_address[station_id] = address\n",
    "\n",
    "                    elif (\"屏東\" in address):\n",
    "                        google_address[station_id] = address\n",
    "                                                \n",
    "                    else:   \n",
    "                        remove_address.append(station_id)\n",
    "                        line = pm25.readline()\n",
    "                        continue\n",
    "                    \n",
    "                    line.append(address)\n",
    "                    outputFile = open(r'E:\\D4SG\\Data\\PM2.5 airbox\\PM2.5國網與中研院屏東縣.csv', 'a', newline='', encoding = \"utf8\")\n",
    "                    outputWriter = csv.writer(outputFile)\n",
    "                    outputWriter.writerow(line)\n",
    "                    outputFile.close()    \n",
    "                    \n",
    "                elif station_id in want_address:\n",
    "                    line.append(want_address.get(station_id))\n",
    "                    outputFile = open(r'E:\\D4SG\\Data\\PM2.5 airbox\\PM2.5國網與中研院屏東縣.csv', 'a', newline='', encoding = \"utf8\")\n",
    "                    outputWriter = csv.writer(outputFile)\n",
    "                    outputWriter.writerow(line)\n",
    "                    outputFile.close()\n",
    "                \n",
    "                elif station_id in google_address:\n",
    "                    line.append(google_address.get(station_id))\n",
    "                    outputFile = open(r'E:\\D4SG\\Data\\PM2.5 airbox\\PM2.5國網與中研院屏東縣.csv', 'a', newline='', encoding = \"utf8\")\n",
    "                    outputWriter = csv.writer(outputFile)\n",
    "                    outputWriter.writerow(line)\n",
    "                    outputFile.close()\n",
    "        \n",
    "        except ValueError:\n",
    "            line.append(\"地址\")\n",
    "            outputFile = open(r'E:\\D4SG\\Data\\PM2.5 airbox\\PM2.5國網與中研院屏東縣.csv', 'a', newline='', encoding = \"utf8\")\n",
    "            outputWriter = csv.writer(outputFile)\n",
    "            outputWriter.writerow(line)\n",
    "            outputFile.close()\n",
    "        \n",
    "        line = pm25.readline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**資料轉小時(小時資料的提供)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ['PM2.5國網與中研院南投縣.csv', 'PM2.5國網與中研院台中市.csv', 'PM2.5國網與中研院台南市.csv', 'PM2.5國網與中研院嘉義縣(市).csv', \n",
    "        'PM2.5國網與中研院基隆市.csv', 'PM2.5國網與中研院大臺北(台北+新北).csv', 'PM2.5國網與中研院屏東縣.csv', 'PM2.5國網與中研院彰化縣(市).csv', \n",
    "         'PM2.5國網與中研院新竹縣(市).csv', 'PM2.5國網與中研院桃園市.csv', 'PM2.5國網與中研院苗栗縣.csv', 'PM2.5國網與中研院雲林縣.csv', \n",
    "        'PM2.5國網與中研院高雄市.csv']\n",
    "\n",
    "import pandas as pd\n",
    "for i in file:\n",
    "    result_table = []\n",
    "    with open(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}\".format(i), encoding = \"utf8\") as openfile:\n",
    "        data_temp = pd.read_csv(openfile, skipinitialspace = True)\n",
    "        \n",
    "        device_id = data_temp.device_id.unique().tolist()\n",
    "        for id in device_id:\n",
    "            revised = data_temp[data_temp['device_id'] == id]\n",
    "            address = revised[\"地址\"].unique().tolist()[0]\n",
    "            latitude = revised[\"latitude\"].unique().tolist()[0]\n",
    "            longitude = revised[\"longitude\"].unique().tolist()[0]\n",
    "\n",
    "            revised = revised[[\"device_id\", \"PM2.5(ug/m3)\", \"PM10\", \"temperature\", \"humidity\", \"new_time\"]]\n",
    "            revised[\"time\"] = pd.to_datetime(revised[\"new_time\"])\n",
    "            \n",
    "            revised = revised.set_index(\"time\").resample('H').mean().interpolate(method = \"linear\")\n",
    "            revised[\"device_id\"] = id\n",
    "            revised[\"latitude\"] = latitude\n",
    "            revised[\"longitude\"] = longitude\n",
    "            revised[\"地址\"] = address\n",
    "            \n",
    "            revised = revised[[\"device_id\", \"PM2.5(ug/m3)\", \"PM10\", \"temperature\", \"humidity\", \"latitude\", \"longitude\", \"地址\"]]\n",
    "            result_table.append(revised)\n",
    "        \n",
    "        result = pd.concat(result_table)\n",
    "        \n",
    "        name = i.strip(\"PM2.5國網與中研院\").strip(\".csv\")\n",
    "        result.to_csv(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}(每小時).csv\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特定季節(15min 資料提供)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_1 = ['PM2.5國網與中研院台中市.csv', 'PM2.5國網與中研院基隆市.csv', 'PM2.5國網與中研院大臺北(台北+新北).csv',\n",
    "          'PM2.5國網與中研院高雄市.csv']\n",
    "\n",
    "file_2 = ['PM2.5國網與中研院南投縣.csv', 'PM2.5國網與中研院台中市.csv', 'PM2.5國網與中研院彰化縣(市).csv', \n",
    "          'PM2.5國網與中研院苗栗縣.csv']\n",
    "\n",
    "import pandas as pd\n",
    "for file in file_1:\n",
    "    with open(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}\".format(file), encoding = \"utf8\") as pm25:\n",
    "        pm25_data = pd.read_csv(pm25, low_memory = False)\n",
    "        \n",
    "        file = file.strip(\".csv\")\n",
    "        table_s1 = []\n",
    "        table_s2 = []\n",
    "        table_s3 = []\n",
    "        table_w1 = []\n",
    "        table_w2 = []\n",
    "        table_w3 = []\n",
    "        want_ids = pm25_data.device_id.unique().copy().tolist()\n",
    "        \n",
    "        for want_id in want_ids:\n",
    "            revised_pd = pm25_data[pm25_data['device_id'] == want_id]\n",
    "            revised_pd = revised_pd[[\"new_time\", \"device_id\", \"PM2.5(ug/m3)\"]]\n",
    "            revised_pd[\"new_time\"] = pd.to_datetime(revised_pd[\"new_time\"])\n",
    "            revised_pd = revised_pd.set_index(\"new_time\").resample('15min').mean().interpolate(method = \"linear\")\n",
    "            revised_pd[want_id] = revised_pd[\"PM2.5(ug/m3)\"]\n",
    "\n",
    "            # 夏季分交通尖峰時段\n",
    "            table_summer = revised_pd.loc['2017-06-15':\"2017-09-04\"]\n",
    "            date_delete = [\"2017-07-26\", \"2017-07-27\", \"2017-07-28\", \"2017-07-29\", \"2017-07-30\", \"2017-07-31\", \n",
    "                           \"2017-08-01\", \"2017-08-02\", \"2017-08-18\", \"2017-08-19\", \"2017-08-20\", \"2017-08-21\", \n",
    "                           \"2017-08-22\", \"2017-08-23\", \"2017-08-24\"]\n",
    "            table_summer = table_summer.loc[~table_summer.index.isin(date_delete)]\n",
    "            stime_1 = table_summer.between_time('07:00', '08:59')\n",
    "            stime_2 = table_summer.between_time('09:00', '15:59')\n",
    "            stime_3 = table_summer.between_time('16:00', '18:59')\n",
    "\n",
    "            stime_1 = stime_1[[want_id]]\n",
    "            table_s1.append(stime_1)     \n",
    "\n",
    "            stime_2 = stime_2[[want_id]]\n",
    "            table_s2.append(stime_2)\n",
    "        \n",
    "            stime_3 = stime_3[[want_id]]\n",
    "            table_s3.append(stime_3)\n",
    "        \n",
    "            #冬季分交通尖峰時段\n",
    "            table_winter = revised_pd.loc['2017-01-01':\"2017-01-31\"]\n",
    "            wtime_1 = table_winter.between_time('07:00', '08:59')\n",
    "            wtime_2 = table_winter.between_time('09:00', '15:59')\n",
    "            wtime_3 = table_winter.between_time('16:00', '18:59')\n",
    "\n",
    "            wtime_1 = wtime_1[[want_id]]\n",
    "            table_w1.append(wtime_1)\n",
    "      \n",
    "            wtime_2 = wtime_2[[want_id]]\n",
    "            table_w2.append(wtime_2)\n",
    "        \n",
    "            wtime_3 = wtime_3[[want_id]]\n",
    "            table_w3.append(wtime_3)\n",
    "                \n",
    "        result_s1 = pd.concat(table_s1, axis=1)\n",
    "        result_s1 = result_s1.dropna(axis = 1)\n",
    "        result_s2 = pd.concat(table_s2, axis=1)\n",
    "        result_s2 = result_s2.dropna(axis = 1)\n",
    "        result_s3 = pd.concat(table_s3, axis=1)\n",
    "        result_s3 = result_s3.dropna(axis = 1)\n",
    "        \n",
    "        result_w1 = pd.concat(table_w1, axis=1)\n",
    "        result_w1 = result_w1.dropna(axis = 1)\n",
    "        result_w2 = pd.concat(table_w2, axis=1)\n",
    "        result_w2 = result_w2.dropna(axis = 1)\n",
    "        result_w3 = pd.concat(table_w3, axis=1)\n",
    "        result_w3 = result_w3.dropna(axis = 1)\n",
    "        \n",
    "        result_w1.to_csv(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}冬季上午.csv\".format(file), encoding = \"utf8\")\n",
    "        result_w2.to_csv(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}冬季中午.csv\".format(file), encoding = \"utf8\")\n",
    "        result_w3.to_csv(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}冬季晚上.csv\".format(file), encoding = \"utf8\")\n",
    "        \n",
    "        result_s1.to_csv(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}夏季上午.csv\".format(file), encoding = \"utf8\")\n",
    "        result_s2.to_csv(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}夏季中午.csv\".format(file), encoding = \"utf8\")\n",
    "        result_s3.to_csv(r\"E:\\D4SG\\Data\\PM2.5 airbox\\各縣市原始資料\\{}夏季晚上.csv\".format(file), encoding = \"utf8\")       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
